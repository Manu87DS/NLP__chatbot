{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP__Chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4db9JYSYV1Mz"
      },
      "source": [
        "## Chatbot text classification approaches\n",
        "* Pattern matchers\n",
        "* Algorithms\n",
        "* Neural networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1sEnXDpWG0_"
      },
      "source": [
        "## Example with Pattern matchers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sX_kBcQLPbRy"
      },
      "source": [
        "# use natural language toolkit + word stemmer\n",
        "import nltk\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "stemmer = LancasterStemmer()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GM0XHsojP5bK",
        "outputId": "d7571986-e28d-47a8-bed0-03e137e8fa4f"
      },
      "source": [
        "# 4 classes of training data\n",
        "training_data = []\n",
        "training_data.append({\"class\":\"greeting\", \"sentence\":\"how are you?\"})\n",
        "training_data.append({\"class\":\"greeting\", \"sentence\":\"how is your day?\"})\n",
        "training_data.append({\"class\":\"greeting\", \"sentence\":\"good day\"})\n",
        "training_data.append({\"class\":\"greeting\", \"sentence\":\"how is it going today?\"})\n",
        "\n",
        "training_data.append({\"class\":\"goodbye\", \"sentence\":\"have a nice day\"})\n",
        "training_data.append({\"class\":\"goodbye\", \"sentence\":\"see you later\"})\n",
        "training_data.append({\"class\":\"goodbye\", \"sentence\":\"have a nice day\"})\n",
        "training_data.append({\"class\":\"goodbye\", \"sentence\":\"talk to you soon\"})\n",
        "\n",
        "training_data.append({\"class\":\"sandwich\", \"sentence\":\"make me a sandwich\"})\n",
        "training_data.append({\"class\":\"sandwich\", \"sentence\":\"can you make a sandwich?\"})\n",
        "training_data.append({\"class\":\"sandwich\", \"sentence\":\"having a sandwich today?\"})\n",
        "training_data.append({\"class\":\"sandwich\", \"sentence\":\"what's for lunch?\"})\n",
        "\n",
        "training_data.append({\"class\":\"salad\", \"sentence\":\"prepare me a salad\"})\n",
        "training_data.append({\"class\":\"salad\", \"sentence\":\"can you prepare a salad?\"})\n",
        "training_data.append({\"class\":\"salad\", \"sentence\":\"lunch with a salad today?\"})\n",
        "training_data.append({\"class\":\"salad\", \"sentence\":\"what's for dinner?\"})\n",
        "\n",
        "print (\"%s sentences of training data\" % len(training_data))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16 sentences of training data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IB4WZrLiRKlM",
        "outputId": "64417abc-808c-4d44-d004-8017d48ebec2"
      },
      "source": [
        "classes = list(set([a['class'] for a in training_data]))\n",
        "classes"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['salad', 'greeting', 'goodbye', 'sandwich']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0baOlYqSRSbL",
        "outputId": "5cebbd68-36f1-4f54-87ee-76cc64630cc9"
      },
      "source": [
        "training_data # liste de dictionnaires"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'class': 'greeting', 'sentence': 'how are you?'},\n",
              " {'class': 'greeting', 'sentence': 'how is your day?'},\n",
              " {'class': 'greeting', 'sentence': 'good day'},\n",
              " {'class': 'greeting', 'sentence': 'how is it going today?'},\n",
              " {'class': 'goodbye', 'sentence': 'have a nice day'},\n",
              " {'class': 'goodbye', 'sentence': 'see you later'},\n",
              " {'class': 'goodbye', 'sentence': 'have a nice day'},\n",
              " {'class': 'goodbye', 'sentence': 'talk to you soon'},\n",
              " {'class': 'sandwich', 'sentence': 'make me a sandwich'},\n",
              " {'class': 'sandwich', 'sentence': 'can you make a sandwich?'},\n",
              " {'class': 'sandwich', 'sentence': 'having a sandwich today?'},\n",
              " {'class': 'sandwich', 'sentence': \"what's for lunch?\"},\n",
              " {'class': 'salad', 'sentence': 'prepare me a salad'},\n",
              " {'class': 'salad', 'sentence': 'can you prepare a salad?'},\n",
              " {'class': 'salad', 'sentence': 'lunch with a salad today?'},\n",
              " {'class': 'salad', 'sentence': \"what's for dinner?\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BcpXy8ZQzhw",
        "outputId": "14b3fa7a-f193-413c-9044-036f3c698f60"
      },
      "source": [
        "nltk.download('punkt')\n",
        "# capture unique stemmed words in the training corpus\n",
        "corpus_words = {}\n",
        "class_words = {}\n",
        "# turn a list into a set (of unique items) and then a list again (this removes duplicates)\n",
        "classes = list(set([a['class'] for a in training_data]))\n",
        "for c in classes:\n",
        "    # prepare a list of words within each class\n",
        "    class_words[c] = []\n",
        "# loop through each sentence in our training data\n",
        "for data in training_data:\n",
        "    # tokenize each sentence into words\n",
        "    for word in nltk.word_tokenize(data['sentence']):\n",
        "        # ignore a some things\n",
        "        if word not in [\"?\", \"'s\"]:\n",
        "            # stem and lowercase each word\n",
        "            stemmed_word = stemmer.stem(word.lower())\n",
        "            # have we not seen this word already?\n",
        "            if stemmed_word not in corpus_words:\n",
        "                corpus_words[stemmed_word] = 1\n",
        "            else:\n",
        "                corpus_words[stemmed_word] += 1\n",
        "            # add the word to our words in class list\n",
        "            class_words[data['class']].extend([stemmed_word])\n",
        "\n",
        "# we now have each stemmed word and the number of occurances of the word in our training corpus (the word's commonality)\n",
        "print (\"Corpus words and counts: %s \\n\" % corpus_words)\n",
        "# also we have all words in each class\n",
        "print (\"Class words: %s\" % class_words)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Corpus words and counts: {'how': 3, 'ar': 1, 'you': 5, 'is': 2, 'yo': 1, 'day': 4, 'good': 1, 'it': 1, 'going': 1, 'today': 3, 'hav': 3, 'a': 8, 'nic': 2, 'see': 1, 'lat': 1, 'talk': 1, 'to': 1, 'soon': 1, 'mak': 2, 'me': 2, 'sandwich': 3, 'can': 2, 'what': 2, 'for': 2, 'lunch': 2, 'prep': 2, 'salad': 3, 'with': 1, 'din': 1} \n",
            "\n",
            "Class words: {'salad': ['prep', 'me', 'a', 'salad', 'can', 'you', 'prep', 'a', 'salad', 'lunch', 'with', 'a', 'salad', 'today', 'what', 'for', 'din'], 'greeting': ['how', 'ar', 'you', 'how', 'is', 'yo', 'day', 'good', 'day', 'how', 'is', 'it', 'going', 'today'], 'goodbye': ['hav', 'a', 'nic', 'day', 'see', 'you', 'lat', 'hav', 'a', 'nic', 'day', 'talk', 'to', 'you', 'soon'], 'sandwich': ['mak', 'me', 'a', 'sandwich', 'can', 'you', 'mak', 'a', 'sandwich', 'hav', 'a', 'sandwich', 'today', 'what', 'for', 'lunch']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9rv_cSlS_Z4"
      },
      "source": [
        "# calculate a score for a given class\n",
        "def calculate_class_score(sentence, class_name, show_details=True):\n",
        "    score = 0\n",
        "    # tokenize each word in our new sentence\n",
        "    for word in nltk.word_tokenize(sentence):\n",
        "        # check to see if the stem of the word is in any of our classes\n",
        "        if stemmer.stem(word.lower()) in class_words[class_name]:\n",
        "            # treat each word with same weight\n",
        "            score += 1\n",
        "            \n",
        "            if show_details:\n",
        "                print (\"   match: %s\" % stemmer.stem(word.lower() ))\n",
        "    return score"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6B3EqxQwTLgF",
        "outputId": "b4e5b8cf-3ee7-4d79-c10d-11173e4c687a"
      },
      "source": [
        "# we can now calculate a score for a new sentence\n",
        "sentence = \"good day for us to have lunch?\"\n",
        "\n",
        "# now we can find the class with the highest score\n",
        "for c in class_words.keys():\n",
        "    print (\"Class: %s  Score: %s \\n\" % (c, calculate_class_score(sentence, c)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   match: for\n",
            "   match: lunch\n",
            "Class: salad  Score: 2 \n",
            "\n",
            "   match: good\n",
            "   match: day\n",
            "Class: greeting  Score: 2 \n",
            "\n",
            "   match: day\n",
            "   match: to\n",
            "   match: hav\n",
            "Class: goodbye  Score: 3 \n",
            "\n",
            "   match: for\n",
            "   match: hav\n",
            "   match: lunch\n",
            "Class: sandwich  Score: 3 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5fX5UI8Tkdj"
      },
      "source": [
        "# calculate a score for a given class taking into account word commonality\n",
        "def calculate_class_score_commonality(sentence, class_name, show_details=True):\n",
        "    score = 0\n",
        "    # tokenize each word in our new sentence\n",
        "    for word in nltk.word_tokenize(sentence):\n",
        "        # check to see if the stem of the word is in any of our classes\n",
        "        if stemmer.stem(word.lower()) in class_words[class_name]:\n",
        "            # treat each word with relative weight\n",
        "            score += (1 / corpus_words[stemmer.stem(word.lower())])\n",
        "\n",
        "            if show_details:\n",
        "                print (\"   match: %s (%s)\" % (stemmer.stem(word.lower()), 1 / corpus_words[stemmer.stem(word.lower())]))\n",
        "    return score"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HisvbeS5T9XJ",
        "outputId": "f6eba3b8-e3ca-4a31-e4bc-6a53fa00d41e"
      },
      "source": [
        "# now we can find the class with the highest score\n",
        "for c in class_words.keys():\n",
        "    print (\"Class: %s  Score: %s \\n\" % (c, calculate_class_score_commonality(sentence, c)))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   match: for (0.5)\n",
            "   match: lunch (0.5)\n",
            "Class: salad  Score: 1.0 \n",
            "\n",
            "   match: good (1.0)\n",
            "   match: day (0.25)\n",
            "Class: greeting  Score: 1.25 \n",
            "\n",
            "   match: day (0.25)\n",
            "   match: to (1.0)\n",
            "   match: hav (0.3333333333333333)\n",
            "Class: goodbye  Score: 1.5833333333333333 \n",
            "\n",
            "   match: for (0.5)\n",
            "   match: hav (0.3333333333333333)\n",
            "   match: lunch (0.5)\n",
            "Class: sandwich  Score: 1.3333333333333333 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F17JHxaEUZoy"
      },
      "source": [
        "# return the class with highest score for sentence\n",
        "def classify(sentence):\n",
        "    high_class = None\n",
        "    high_score = 0\n",
        "    # loop through our classes\n",
        "    for c in class_words.keys():\n",
        "        # calculate score of sentence for each class\n",
        "        score = calculate_class_score_commonality(sentence, c, show_details=False)\n",
        "        # keep track of highest score\n",
        "        if score > high_score:\n",
        "            high_class = c\n",
        "            high_score = score\n",
        "\n",
        "    return high_class, high_score"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86fcBkgUUtUP",
        "outputId": "dfef69f9-9a49-49d3-d8ef-310f00e9d36a"
      },
      "source": [
        "classify(\"make me some  lunch?\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('sandwich', 1.5)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsnX_Ds3UzIM",
        "outputId": "cc3798bd-9e5e-4817-80a9-16f30d23ebda"
      },
      "source": [
        "classify(\"prepare me some lunch?\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('salad', 1.5)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ros5biGmU6yj",
        "outputId": "b18693d6-3967-4329-9b3a-d1c7c2703eb3"
      },
      "source": [
        "classify(\"make me some dinner?\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('salad', 1.5)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eqez0OSUVIPg",
        "outputId": "a27aedfb-9451-4a1e-a452-24feca28cafa"
      },
      "source": [
        "classify(\"talk to you tommorow\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('goodbye', 2.2)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}